import streamlit as st
import tempfile
import cv2
import numpy as np
import pandas as pd
import os
import time
from ultralytics import YOLO
import matplotlib.pyplot as plt
from PIL import Image

st.set_page_config(page_title="é¼»ãƒˆãƒ©ãƒƒã‚«ãƒ¼", layout="wide")
st.title("ğŸ­ é¼»ãƒˆãƒ©ãƒƒã‚«ãƒ¼ & è¡Œå‹•é‡è§£æã‚¢ãƒ—ãƒªï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰")

# -----------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -----------------------------------
def filter_nose_boxes(boxes, frame_w, frame_h,
                      roi_y_max_pct, min_area_pct, max_area_pct,
                      min_ar, max_ar):
    """
    boxes: Ultralytics Boxes
    è¿”ã‚Šå€¤: [(x,y,conf,w,h), ...]ï¼ˆæ¡ä»¶ã‚’æº€ãŸã™å€™è£œã®ã¿ï¼‰
    """
    if boxes is None or boxes.xywh is None:
        return []

    y_max_abs = roi_y_max_pct * frame_h  # ã“ã®Yã‚ˆã‚Šä¸‹ã¯æ¨ã¦ã‚‹
    min_area_abs = min_area_pct * (frame_w * frame_h)
    max_area_abs = max_area_pct * (frame_w * frame_h)

    kept = []
    for i in range(len(boxes)):
        cls_id = int(boxes.cls[i].item())
        if cls_id != 0:  # é¼»ã‚¯ãƒ©ã‚¹ã®ã¿
            continue
        x = float(boxes.xywh[i][0].item())
        y = float(boxes.xywh[i][1].item())
        w = float(boxes.xywh[i][2].item())
        h = float(boxes.xywh[i][3].item())
        conf = float(boxes.conf[i].item())

        # ROI: ä¸‹å´ï¼ˆè¶³ãŒå†™ã‚ŠãŒã¡ï¼‰ã‚’ç„¡è¦–
        if y > y_max_abs:
            continue

        area = w * h
        if not (min_area_abs <= area <= max_area_abs):
            continue

        ar = w / (h + 1e-6)
        if not (min_ar <= ar <= max_ar):
            continue

        kept.append((x, y, conf, w, h))
    return kept


def ema(prev_pt, curr_pt, alpha=0.5):
    """æŒ‡æ•°ç§»å‹•å¹³å‡ã§ä½ç½®ã‚’ãªã‚ã‚‰ã‹ã«ã™ã‚‹"""
    if prev_pt is None:
        return curr_pt
    px, py = prev_pt
    cx, cy = curr_pt
    return (alpha * cx + (1 - alpha) * px, alpha * cy + (1 - alpha) * py)


# -----------------------------------
# ã‚¿ãƒ–ã®ä½œæˆ
# -----------------------------------
tabs = st.tabs(["ğŸ“¥ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“Š è§£æçµæœ", "ğŸ–¼ï¸ ç”»åƒæ¨è«–", "âš™ï¸ è¨­å®š", "ğŸ§ª é–‹ç™ºä¸­"])

DEFAULT_MODEL_PATH = "runs/detect/train_debug/weights/best.pt"

# -----------------------------------
# ğŸ“¥ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¿ãƒ–
# -----------------------------------
with tabs[0]:
    st.header("å‹•ç”»ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov", "avi", "mts"])

    if uploaded_file:
        st.video(uploaded_file)
        st.success("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=uploaded_file.name) as tmp:
            tmp.write(uploaded_file.read())
            video_path = tmp.name

        # ç”»åƒæŠ½å‡ºï¼ˆ1ç§’æ¯ï¼‰
        if st.button("ã“ã®å‹•ç”»ã‹ã‚‰1ç§’ã”ã¨ã«ç”»åƒæŠ½å‡º"):
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_interval = max(1, int(fps))
            frame_count = 0
            saved_count = 0

            base_name = os.path.splitext(uploaded_file.name)[0]
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_dir = f"mouse_nose_dataset/images/train/{base_name}_{timestamp}"
            os.makedirs(output_dir, exist_ok=True)

            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                if frame_count % frame_interval == 0:
                    filename = f"frame_{saved_count:04}.jpg"
                    filepath = os.path.join(output_dir, filename)
                    cv2.imwrite(filepath, frame)
                    saved_count += 1
                frame_count += 1

            cap.release()
            st.success(f"{saved_count} æšã®ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ä¿å­˜å…ˆ: {output_dir}")

        st.subheader("é¼»å…ˆæ¤œå‡ºã¨ç§»å‹•è·é›¢è§£æï¼ˆç²¾åº¦ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä»˜ãï¼‰")

        # ãƒ¢ãƒ‡ãƒ«
        model_path_ui = st.text_input("å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹", value=DEFAULT_MODEL_PATH)
        model = YOLO(model_path_ui)
        st.caption(f"ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ©ã‚¹å: {getattr(model, 'names', {0: 'nose'})}")

        # æ¨è«–ãƒ»åˆ¶ç´„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        left, right = st.columns(2)
        with left:
            base_conf = st.slider("åŸºæœ¬confã—ãã„å€¤", 0.01, 0.70, 0.20, 0.01)
            min_conf = st.slider("æœ€å°confï¼ˆè¦‹å¤±ã„æ™‚ã«ä¸€æ™‚çš„ã«ä¸‹ã’ã‚‹ä¸‹é™ï¼‰", 0.01, 0.70, 0.10, 0.01)
            imgsz = st.selectbox("æ¨è«–è§£åƒåº¦ (imgsz)", [320, 480, 640, 800], index=2)
            ema_alpha = st.slider("å¹³æ»‘åŒ–(EMA) Î±", 0.05, 0.95, 0.40, 0.05)
            patience_frames = st.number_input("æ¤œå‡ºãŒæ¶ˆãˆã¦ã‚‚ä½ç½®ä¿æŒã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°", 0, 30, 5, 1)
            max_jump_px = st.number_input("1ãƒ•ãƒ¬ãƒ¼ãƒ ã®æœ€å¤§è¨±å®¹ç§»å‹•é‡(px)", 1, 500, 60, 1)
        with right:
            roi_y_max_pct = st.slider("æœ‰åŠ¹ROIã®é«˜ã•(ä¸Šã‹ã‚‰ã®å‰²åˆ) â€»ä¸‹å´ç„¡è¦–", 0.10, 1.00, 0.80, 0.05)
            min_area_pct = st.slider("æœ€å°ãƒœãƒƒã‚¯ã‚¹é¢ç©(ç”»ç´ æ¯”)", 0.00001, 0.01, 0.0002, 0.00001, format="%.5f")
            max_area_pct = st.slider("æœ€å¤§ãƒœãƒƒã‚¯ã‚¹é¢ç©(ç”»ç´ æ¯”)", 0.001, 0.20, 0.02, 0.001, format="%.3f")
            min_ar = st.slider("æœ€å°ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” w/h", 0.10, 2.00, 0.50, 0.05)
            max_ar = st.slider("æœ€å¤§ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” w/h", 0.50, 4.00, 2.00, 0.05)
            show_preview = st.checkbox("ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºï¼ˆé…ããªã‚Šã¾ã™ï¼‰", value=False)

        # ã‚¹ã‚±ãƒ¼ãƒ«
        pixels_per_cm = float(st.session_state.get("pixels_per_cm", 79.1))
        threshold_px = float(st.session_state.get("threshold", 2.0))

        # è§£æãƒ«ãƒ¼ãƒ—
        cap = cv2.VideoCapture(video_path)
        frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps_in = cap.get(cv2.CAP_PROP_FPS)
        st.write("è§£æä¸­... ãŠå¾…ã¡ãã ã•ã„")

        # è»Œè·¡å‹•ç”»å‡ºåŠ›
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out_path = "trajectory_output.mp4"
        out = cv2.VideoWriter(out_path, fourcc, max(1.0, fps_in), (frame_w, frame_h))

        prev_nose = None          # EMAå¾Œã®ä½ç½®
        last_det = None           # ç›´è¿‘ã®ã€Œæ¤œå‡ºã•ã‚ŒãŸã€ä½ç½®ï¼ˆEMAå‰å¾Œã©ã¡ã‚‰ã§ã‚‚OKï¼‰
        no_det_count = 0
        total_distance = 0.0
        frame_distances, frame_ids = [], []
        frame_idx = 0
        conf_curr = base_conf     # é©å¿œconf

        trajectory_points = []

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # æ¨è«–
            results = model.predict(source=frame, conf=conf_curr, imgsz=imgsz, verbose=False)
            r0 = results[0]
            candidates = filter_nose_boxes(
                r0.boxes, frame_w, frame_h,
                roi_y_max_pct, min_area_pct, max_area_pct,
                min_ar, max_ar
            )

            # æœ€è‰¯ï¼ˆconfæœ€å¤§ï¼‰å€™è£œ
            if len(candidates) > 0:
                x, y, conf, bw, bh = max(candidates, key=lambda t: t[2])
                curr_det = (x, y)
                last_det = curr_det
                no_det_count = 0
                # æ¤œå‡ºã§ããŸã‚‰confã‚’ãƒ™ãƒ¼ã‚¹å€¤ã«æˆ»ã™
                conf_curr = base_conf
            else:
                curr_det = None
                no_det_count += 1
                # è¦‹å¤±ã„æ™‚ã¯ä¸€æ™‚çš„ã«ã—ãã„å€¤ã‚’ä¸‹ã’ã¦å†æ¢ç´¢
                if no_det_count <= patience_frames:
                    # ç›´è¿‘ä½ç½®ã‚’ä¿æŒï¼ˆè·é›¢ã¯å¾Œã§åˆ¤å®šï¼‰
                    pass
                else:
                    # ã•ã‚‰ã«è¦‹å¤±ã„ãŒç¶šããªã‚‰ã€confã‚’å°‘ã—ãšã¤ min_conf ã¾ã§ä¸‹ã’ã‚‹
                    conf_curr = max(min_conf, conf_curr - 0.05)

            # ä½ç½®æ±ºå®šï¼šæ¤œå‡ºãªã‘ã‚Œã° last_det ã‚’ä»®ä½ç½®ã«ã—ã¦EMA
            raw_target = curr_det if curr_det is not None else last_det
            if raw_target is not None:
                smoothed = ema(prev_nose, raw_target, alpha=ema_alpha)
            else:
                smoothed = None

            # è·é›¢åŠ ç®—ï¼ˆã‚¸ãƒ£ãƒ³ãƒ—æŠ‘åˆ¶ï¼†æœ€å°è·é›¢ï¼‰
            if smoothed is not None and prev_nose is not None:
                dist_px = float(np.linalg.norm(np.array(smoothed) - np.array(prev_nose)))
                if dist_px <= max_jump_px and dist_px >= threshold_px:
                    total_distance += dist_px
                    frame_distances.append(total_distance / pixels_per_cm)
                    frame_ids.append(frame_idx)

            # è»Œè·¡æç”»ï¼†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            vis = frame.copy()
            if smoothed is not None:
                trajectory_points.append(smoothed)
                cv2.circle(vis, (int(smoothed[0]), int(smoothed[1])), 6, (0, 255, 0), -1)
            # è»Œè·¡ç·š
            for i in range(1, len(trajectory_points)):
                pt1 = (int(trajectory_points[i-1][0]), int(trajectory_points[i-1][1]))
                pt2 = (int(trajectory_points[i][0]), int(trajectory_points[i][1]))
                cv2.line(vis, pt1, pt2, (0, 255, 255), 2)

            # ROIå¯è¦–åŒ–ï¼ˆä¸‹å´ã‚’ãƒã‚¹ã‚¯ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ï¼‰
            roi_line_y = int(roi_y_max_pct * frame_h)
            cv2.line(vis, (0, roi_line_y), (frame_w, roi_line_y), (255, 0, 0), 1)

            # å‡ºåŠ›å‹•ç”»ã¸
            out.write(vis)

            if show_preview:
                st.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), caption=f"Frame {frame_idx} preview", use_column_width=True)

            prev_nose = smoothed if smoothed is not None else prev_nose
            frame_idx += 1

        cap.release()
        out.release()

        # çµæœä¿å­˜
        total_cm = total_distance / pixels_per_cm
        df = pd.DataFrame({"Frame": frame_ids, "Distance_cm": frame_distances})
        st.session_state["result_df"] = df
        st.session_state["total_cm"] = total_cm

        st.success(f"ç·ç§»å‹•è·é›¢: {total_cm:.2f} cm")
        st.subheader("ğŸ¬ è»Œè·¡ã¤ãå‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.video(out_path)
        st.download_button("è»Œè·¡å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=open(out_path, "rb").read(),
                           file_name="trajectory_output.mp4", mime="video/mp4")

# -----------------------------------
# ğŸ“Š è§£æçµæœã‚¿ãƒ–
# -----------------------------------
with tabs[1]:
    st.header("è§£æçµæœ")
    if "result_df" in st.session_state:
        df = st.session_state["result_df"]
        fig, ax = plt.subplots()
        ax.plot(df["Frame"], df["Distance_cm"], label="ç´¯ç©è·é›¢(cm)")
        ax.set_xlabel("ãƒ•ãƒ¬ãƒ¼ãƒ ")
        ax.set_ylabel("è·é›¢(cm)")
        ax.set_title("ç§»å‹•è·é›¢ã®æ¨ç§»")
        ax.legend()
        st.pyplot(fig)

        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, file_name="distance_data.csv", mime="text/csv")
        st.metric("ç·ç§»å‹•è·é›¢", f"{st.session_state['total_cm']:.2f} cm")
    else:
        st.info("ğŸ“¥ ã‚¿ãƒ–ã‹ã‚‰å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ã—ã¦è§£æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")

# -----------------------------------
# ğŸ–¼ï¸ ç”»åƒæ¨è«–ã‚¿ãƒ–
# -----------------------------------
with tabs[2]:
    st.header("ç”»åƒã‹ã‚‰ã®é¼»å…ˆæ¤œå‡º")
    model_path_img = st.text_input("å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ï¼ˆç”»åƒç”¨ï¼‰", value=DEFAULT_MODEL_PATH)
    model_img = YOLO(model_path_img)
    image_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])

    if image_file is not None:
        image = Image.open(image_file)
        st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
            image.save(tmp.name)
            tmp_path = tmp.name

        results = model_img.predict(tmp_path, save=False, conf=0.25)
        result_img = results[0].plot()
        st.image(result_img, caption="æ¤œå‡ºçµæœ", use_column_width=True)

        st.subheader("æ¤œå‡ºã•ã‚ŒãŸãƒœãƒƒã‚¯ã‚¹æƒ…å ±")
        for box in results[0].boxes.xyxy.cpu().numpy():
            st.write(f"X1: {box[0]:.2f}, Y1: {box[1]:.2f}, X2: {box[2]:.2f}, Y2: {box[3]:.2f}")

# -----------------------------------
# âš™ï¸ è¨­å®šã‚¿ãƒ–
# -----------------------------------
with tabs[3]:
    st.header("è¨­å®š")
    st.session_state["pixels_per_cm"] = st.number_input("1cmã‚ãŸã‚Šã®ãƒ”ã‚¯ã‚»ãƒ«æ•°", value=79.1, step=0.1)
    st.session_state["threshold"] = st.number_input("ç§»å‹•ã¨åˆ¤å®šã™ã‚‹æœ€å°è·é›¢ï¼ˆpxï¼‰", value=2.0, step=0.1)

# -----------------------------------
# ğŸ§ª é–‹ç™ºä¸­ã‚¿ãƒ–
# -----------------------------------
with tabs[4]:
    st.header("é–‹ç™ºä¸­æ©Ÿèƒ½")
    st.warning("ä»Šå¾Œã“ã“ã«ã€æ–°ãŸãªæ©Ÿèƒ½ã‚’è¿½åŠ äºˆå®šã§ã™ï¼")



    